# -*- coding: utf-8 -*-
"""TASK 5 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LtpToHA8q9lmYcnXd0HICAuTMrLdAnJt

WITHOUT MARL:
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, confusion_matrix
from imblearn.over_sampling import SMOTE

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: 'Syn', 'NetBIOS', and 'LDAP' to 1, others to 0
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x in ['Syn', 'NetBIOS', 'LDAP'] else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = (y == 1).astype(int)

# Introduce class imbalance and further imbalance it
imbalance_ratio = 0.02
positive_indices = y_transformed[y_transformed == 1].index
num_positive_samples = len(positive_indices)
num_negative_samples_to_keep = min(int(num_positive_samples / imbalance_ratio), len(y_transformed[y_transformed == 0]))
negative_indices_to_keep = np.random.choice(y_transformed[y_transformed == 0].index, size=num_negative_samples_to_keep, replace=False)
indices_to_keep = np.concatenate([positive_indices, negative_indices_to_keep])
X_imbalanced = X_scaled[indices_to_keep]
y_imbalanced = y_transformed[indices_to_keep]

# Introduce noise to the features
noise_factor = 0.2  # Increased noise factor
X_imbalanced += noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_imbalanced.shape)

# Drop more important features
num_features_to_drop = 10  # Dropping more features
important_features = np.argsort(np.var(X_imbalanced, axis=0))[-num_features_to_drop:]  # Assuming high variance features are important
X_imbalanced = np.delete(X_imbalanced, important_features, axis=1)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

test_accuracies_lr = []
false_positives_lr = []

for train_index, test_index in kf.split(X_imbalanced):
    X_train, X_test = X_imbalanced[train_index], X_imbalanced[test_index]
    y_train, y_test = y_imbalanced[train_index], y_imbalanced[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate test accuracy for LogisticRegression
    test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)
    test_accuracies_lr.append(test_accuracy_lr)

    # Calculate false positives for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)
    false_positives_lr.append(conf_matrix_lr[0][1])

# Print results for LogisticRegression
print("\nK-Fold Cross-Validation Results for LogisticRegression:")
print("Test Accuracies:", test_accuracies_lr)
print("Mean Test Accuracy:", sum(test_accuracies_lr) / len(test_accuracies_lr))
print("False Positives:", false_positives_lr)

"""WITH MARL:"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import RFE

class MARLAgent:
    def __init__(self, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):
        self.num_actions = num_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_values = {}

    def choose_action(self, state):
        if np.random.rand() < self.epsilon:
            return np.random.choice(self.num_actions)
        else:
            if state in self.q_values:
                return np.argmax(self.q_values[state])
            else:
                return np.random.choice(self.num_actions)

    def update_q_value(self, state, action, reward, next_state):
        if state not in self.q_values:
            self.q_values[state] = np.zeros(self.num_actions)
        if next_state not in self.q_values:
            self.q_values[next_state] = np.zeros(self.num_actions)
        self.q_values[state][action] += self.learning_rate * (
            reward + self.discount_factor * np.max(self.q_values[next_state]) - self.q_values[state][action])

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: 'Syn', 'NetBIOS', and 'LDAP' to 1, others to 0
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x in ['Syn', 'NetBIOS', 'LDAP'] else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = (y == 1).astype(int)

# Introduce class imbalance
# Keep only a small fraction of positive examples (class 1)
imbalance_ratio = 0.1
positive_indices = y_transformed[y_transformed == 1].index
num_positive_samples = len(positive_indices)
num_negative_samples_to_keep = min(int(num_positive_samples / imbalance_ratio), len(y_transformed[y_transformed == 0]))
negative_indices_to_keep = np.random.choice(y_transformed[y_transformed == 0].index, size=num_negative_samples_to_keep, replace=False)
indices_to_keep = np.concatenate([positive_indices, negative_indices_to_keep])
X_imbalanced = X_scaled[indices_to_keep]
y_imbalanced = y_transformed[indices_to_keep]

# Use SMOTE to handle imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_imbalanced, y_imbalanced)

# Introduce more noise to the features
noise_factor = 0.5  # Increase noise factor
X_resampled += noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_resampled.shape)

# Drop less important features
num_features_to_drop = 30  # Dropping more features
important_features = np.argsort(np.var(X_resampled, axis=0))[-num_features_to_drop:]  # Assuming high variance features are important
X_resampled = np.delete(X_resampled, important_features, axis=1)

# Initialize MARL agents
num_agents = 5
num_actions_per_agent = 3  # Example: actions could be adjusting learning rates, adding/removing features, etc.
agents = [MARLAgent(num_actions=num_actions_per_agent) for _ in range(num_agents)]

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

test_accuracies_lr = []
false_positives_lr = []

for train_index, test_index in kf.split(X_resampled):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # Feature selection using RFE
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    rfe = RFE(estimator=lr_model, n_features_to_select=10, step=1)  # Select fewer features
    X_train_rfe = rfe.fit_transform(X_train, y_train)
    X_test_rfe = rfe.transform(X_test)

    for episode in range(100):
        # Agents choose actions (e.g., modify learning rate, select features, etc.)
        actions = [agent.choose_action(state=0) for agent in agents]  # Simplified: all agents in state 0

        # Perform actions (adjust learning rates as an example)
        learning_rate_adjustments = [0.001, 0.01, 0.1]  # Smaller range for regularization parameter
        for action in actions:
            lr_model.set_params(C=learning_rate_adjustments[action])  # Adjust the regularization parameter

        # Fit the model
        lr_model.fit(X_train_rfe, y_train)

        # Evaluate the model
        y_test_pred_lr = lr_model.predict(X_test_rfe)

        # Calculate reward (e.g., accuracy)
        test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)

        # Update Q-values based on the reward
        for agent in agents:
            agent.update_q_value(state=0, action=actions[0], reward=test_accuracy_lr, next_state=0)

    # Final evaluation for the current fold
    y_test_pred_lr = lr_model.predict(X_test_rfe)
    test_accuracy_lr = accuracy_score(y_test, y_test_pred_lr)
    test_accuracies_lr.append(test_accuracy_lr)

    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)
    false_positives_lr.append(conf_matrix_lr[0][1])

# Print results for LogisticRegression
print("\nK-Fold Cross-Validation Results for LogisticRegression with MARL:")
print("Test Accuracies:", test_accuracies_lr)
print("Mean Test Accuracy:", sum(test_accuracies_lr) / len(test_accuracies_lr))
print("False Positives:", false_positives_lr)