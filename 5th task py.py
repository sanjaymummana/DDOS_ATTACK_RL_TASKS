# -*- coding: utf-8 -*-
"""TASK 5 .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LtpToHA8q9lmYcnXd0HICAuTMrLdAnJt

WITHOUT MARL:
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
accuracies = []
confusion_matrices = []

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    accuracies.append(accuracy)
    confusion_matrices.append(conf_matrix_lr)

    # Print confusion matrix for each fold
    print(f"\nConfusion Matrix - Fold {fold+1}:")
    print(conf_matrix_lr)

# Print average accuracy across all folds
average_accuracy = np.mean(accuracies)
print(f"\nAverage Accuracy across all folds: {average_accuracy:.4f}")

# Print accuracies for each fold
for i, accuracy in enumerate(accuracies):
    print(f"Accuracy - Fold {i+1}: {accuracy:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    confusion_matrices.append(conf_matrix_lr)

    # Print confusion matrix for each fold
    print(f"\nConfusion Matrix - Fold {fold+1}:")
    print(conf_matrix_lr)

# Print average accuracies across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")

# Print accuracies for each fold
for i, (train_accuracy, test_accuracy) in enumerate(zip(train_accuracies, test_accuracies)):
    print(f"Fold {i+1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score
from imblearn.over_sampling import RandomOverSampler

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use RandomOverSampler to handle class imbalance
oversampler = RandomOverSampler(random_state=42)
X_resampled, y_resampled = oversampler.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    confusion_matrices.append(conf_matrix_lr)

    # Print confusion matrix for each fold
    print(f"\nConfusion Matrix - Fold {fold+1}:")
    print(conf_matrix_lr)

# Print average accuracies across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")

# Print accuracies for each fold
for i, (train_accuracy, test_accuracy) in enumerate(zip(train_accuracies, test_accuracies)):
    print(f"Fold {i+1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from imblearn.over_sampling import SMOTE

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []
precisions = []
recalls = []
f1_scores = []

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Calculate precision, recall, F1-score
    report = classification_report(y_test, y_test_pred_lr, target_names=['Benign', 'Syn'], output_dict=True)
    precision = report['Syn']['precision']
    recall = report['Syn']['recall']
    f1 = report['Syn']['f1-score']

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    confusion_matrices.append(conf_matrix_lr)
    precisions.append(precision)
    recalls.append(recall)
    f1_scores.append(f1)

    # Print confusion matrix and metrics for each fold
    print(f"\nConfusion Matrix - Fold {fold+1}:")
    print(conf_matrix_lr)
    print(f"Precision - Fold {fold+1}: {precision:.4f}")
    print(f"Recall - Fold {fold+1}: {recall:.4f}")
    print(f"F1-score - Fold {fold+1}: {f1:.4f}")

# Print average metrics across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
average_precision = np.mean(precisions)
average_recall = np.mean(recalls)
average_f1_score = np.mean(f1_scores)

print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")
print(f"Average Precision across all folds: {average_precision:.4f}")
print(f"Average Recall across all folds: {average_recall:.4f}")
print(f"Average F1-score across all folds: {average_f1_score:.4f}")

# Print metrics for each fold
for i, (train_accuracy, test_accuracy, precision, recall, f1) in enumerate(zip(train_accuracies, test_accuracies, precisions, recalls, f1_scores)):
    print(f"\nFold {i+1} Metrics:")
    print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
    print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE

class MARLAgent:
    def __init__(self, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):
        self.num_actions = num_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_values = {}

    def choose_action(self, state):
        if np.random.rand() < self.epsilon:
            return np.random.choice(self.num_actions)
        else:
            if state in self.q_values:
                return np.argmax(self.q_values[state])
            else:
                return np.random.choice(self.num_actions)

    def update_q_value(self, state, action, reward, next_state):
        if state not in self.q_values:
            self.q_values[state] = np.zeros(self.num_actions)
        if next_state not in self.q_values:
            self.q_values[next_state] = np.zeros(self.num_actions)
        self.q_values[state][action] += self.learning_rate * (
            reward + self.discount_factor * np.max(self.q_values[next_state]) - self.q_values[state][action])

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []

# Initialize MARLAgent with 3 possible actions (representing 3 different C values for Logistic Regression)
agent = MARLAgent(num_actions=3)
C_values = [0.01, 0.1, 1]

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # Use MARLAgent to choose the action (hyperparameter)
    state = fold  # Example state, can be more sophisticated
    action = agent.choose_action(state)
    C_value = C_values[action]

    # LogisticRegression Model Training with chosen C value
    lr_model = LogisticRegression(C=C_value, max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    confusion_matrices.append(conf_matrix_lr)

    # Update MARLAgent based on the result
    next_state = fold + 1  # Example next state
    reward = test_accuracy  # Use test accuracy as the reward
    agent.update_q_value(state, action, reward, next_state)

    # Print confusion matrix for each fold
    print(f"\nConfusion Matrix - Fold {fold+1} with C={C_value}:")
    print(conf_matrix_lr)

# Print average accuracies across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")

# Print accuracies for each fold
for i, (train_accuracy, test_accuracy) in enumerate(zip(train_accuracies, test_accuracies)):
    print(f"Fold {i+1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score

# MARL Agent class
class MARLAgent:
    def __init__(self, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):
        self.num_actions = num_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_values = {}

    def choose_action(self, state):
        if np.random.rand() < self.epsilon:
            return np.random.choice(self.num_actions)
        else:
            if state in self.q_values:
                return np.argmax(self.q_values[state])
            else:
                return np.random.choice(self.num_actions)

    def update_q_value(self, state, action, reward, next_state):
        if state not in self.q_values:
            self.q_values[state] = np.zeros(self.num_actions)
        if next_state not in self.q_values:
            self.q_values[next_state] = np.zeros(self.num_actions)
        self.q_values[state][action] += self.learning_rate * (
            reward + self.discount_factor * np.max(self.q_values[next_state]) - self.q_values[state][action])

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int).reset_index(drop=True)  # Reset indices to align with X_scaled

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []

# Initialize MARL agent
marl_agent = MARLAgent(num_actions=2, learning_rate=0.1, discount_factor=0.9, epsilon=0.1)

for fold, (train_index, test_index) in enumerate(kf.split(X_scaled)):
    X_train, X_test = X_scaled[train_index], X_scaled[test_index]
    y_train, y_test = y_transformed[train_index], y_transformed[test_index]

    # LogisticRegression Model Training
    lr_model = LogisticRegression(max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate accuracy for this fold
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    # Print confusion matrix for each fold
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)
    print(f"\nConfusion Matrix - Fold {fold+1}:")
    print(conf_matrix_lr)

    # Update MARL agent Q-values based on test accuracy
    reward = test_accuracy  # Use accuracy as reward
    marl_agent.update_q_value(fold, 0, reward, fold + 1)  # Example of state and action

# Print average accuracies across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")

# Print accuracies for each fold
for i, (train_accuracy, test_accuracy) in enumerate(zip(train_accuracies, test_accuracies)):
    print(f"Fold {i+1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Print average Q-values
print("\nAverage Q-values:")
for state in range(5):  # Assuming 5 states based on 5 folds
    if state in marl_agent.q_values:
        print(f"State {state}: Q-values {marl_agent.q_values[state]}")
    else:
        print(f"State {state}: Q-values not updated")

import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE

class MARLAgent:
    def __init__(self, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.2):
        self.num_actions = num_actions
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        self.q_values = {}

    def choose_action(self, state):
        if np.random.rand() < self.epsilon:
            return np.random.choice(self.num_actions)
        else:
            if state in self.q_values:
                return np.argmax(self.q_values[state])
            else:
                return np.random.choice(self.num_actions)

    def update_q_value(self, state, action, reward, next_state):
        if state not in self.q_values:
            self.q_values[state] = np.zeros(self.num_actions)
        if next_state not in self.q_values:
            self.q_values[next_state] = np.zeros(self.num_actions)
        self.q_values[state][action] += self.learning_rate * (
            reward + self.discount_factor * np.max(self.q_values[next_state]) - self.q_values[state][action])

# List of file paths
file_paths = [
    '/content/DrDoS_DNS.csv', '/content/DrDoS_LDAP.csv', '/content/DrDoS_MSSQL.csv',
    '/content/DrDoS_NTP.csv', '/content/DrDoS_NetBIOS.csv', '/content/DrDoS_SSDP.csv',
    '/content/Syn.csv', '/content/UDPLag.csv', '/content/Syn_2019_1-12.csv'
]

# Initialize an empty list to store dataframes
dataframes = []

# Read each CSV file and append to the list
for file_path in file_paths:
    df = pd.read_csv(file_path)
    dataframes.append(df)

# Concatenate all dataframes into one
combined_data = pd.concat(dataframes, ignore_index=True)

# Transform 'Label' column: keep 'Syn' as 1, 'Benign' as 0, and drop the rest
combined_data = combined_data[combined_data[' Label'].isin(['Syn', 'BENIGN'])]
combined_data[' Label'] = combined_data[' Label'].map(lambda x: 1 if x == 'Syn' else 0)

# Verify class distribution
print("Class distribution:\n", combined_data[' Label'].value_counts())

# Check for duplicates and drop them
combined_data = combined_data.drop_duplicates()

# Verify the class distribution again after dropping duplicates
print("Class distribution after dropping duplicates:\n", combined_data[' Label'].value_counts())

# Split data into features and target variable
X = combined_data.drop(' Label', axis=1)
y = combined_data[' Label']

# Convert non-numeric columns to numeric
X_numeric = X.apply(pd.to_numeric, errors='coerce')

# Replace infinite values with NaNs
X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)

# Handle missing values by imputing with the mean
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X_numeric)

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Transform label column
y_transformed = y.astype(int)

# Use SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_scaled, y_transformed)

# K-Fold Cross-Validation with 5 folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Initialize lists to store results
train_accuracies = []
test_accuracies = []
confusion_matrices = []

# Initialize MARLAgent with more possible actions (representing more different C values for Logistic Regression)
agent = MARLAgent(num_actions=5)
C_values = [0.001, 0.01, 0.1, 1, 10]

for fold, (train_index, test_index) in enumerate(kf.split(X_resampled)):
    X_train, X_test = X_resampled[train_index], X_resampled[test_index]
    y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # Use MARLAgent to choose the action (hyperparameter)
    state = (fold, np.mean(train_accuracies) if train_accuracies else 0)  # Example state, can be more sophisticated
    action = agent.choose_action(state)
    C_value = C_values[action]

    # LogisticRegression Model Training with chosen C value
    lr_model = LogisticRegression(C=C_value, max_iter=1000, random_state=42)
    lr_model.fit(X_train, y_train)

    # LogisticRegression Model Evaluation
    y_train_pred_lr = lr_model.predict(X_train)
    y_test_pred_lr = lr_model.predict(X_test)

    # Calculate confusion matrix for LogisticRegression
    conf_matrix_lr = confusion_matrix(y_test, y_test_pred_lr)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred_lr)
    test_accuracy = accuracy_score(y_test, y_test_pred_lr)

    # Store results
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    confusion_matrices.append(conf_matrix_lr)

    # Update MARLAgent based on the result
    next_state = (fold + 1, train_accuracy)  # Example next state
    reward = test_accuracy  # Use test accuracy as the reward
    agent.update_q_value(state, action, reward, next_state)

    # Print confusion matrix for each fold
    print(f"\nConfusion Matrix - Fold {fold+1} with C={C_value}:")
    print(conf_matrix_lr)

# Print average accuracies across all folds
average_train_accuracy = np.mean(train_accuracies)
average_test_accuracy = np.mean(test_accuracies)
print(f"\nAverage Train Accuracy across all folds: {average_train_accuracy:.4f}")
print(f"Average Test Accuracy across all folds: {average_test_accuracy:.4f}")

# Print accuracies for each fold
for i, (train_accuracy, test_accuracy) in enumerate(zip(train_accuracies, test_accuracies)):
    print(f"Fold {i+1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")